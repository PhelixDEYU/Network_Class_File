{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -U pypdf faiss-cpu\n",
    "! pip install -q -U InstructorEmbedding\n",
    "! pip install huggingface_hub -q \n",
    "! pip install gradio -q \n",
    "! pip install langchain==0.1.2 \n",
    "! pip install sentence_transformers==2.2.2\n",
    "! pip install transformers\n",
    "! pip install diffusers\n",
    "! pip install accelerate\n",
    "! pip install datasets\n",
    "! pip install --upgrade pip\n",
    "! pip install --upgrade transformers accelerate datasets[audio]\n",
    "! pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n",
    "! pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade git+https://github.com/huggingface/transformers.git accelerate datasets[audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"washeed/audio-transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"washeed/audio-transcribe\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"washeed/audio-transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# 加载音频文件\n",
    "audio_file = \"/Users/deyu/Documents/GitHub/Network_Class_File/Network_Class_File/illusion.wav\"\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# 提取 MFCC 特征\n",
    "mfccs = librosa.feature.mfcc(y=waveform, sr=sample_rate)\n",
    "\n",
    "# 打印特征矩阵的形状\n",
    "print(\"MFCCs shape:\", mfccs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"washeed/audio-transcribe\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已將輸出的文本保存到 original_lyrics.txt 文件中\n"
     ]
    }
   ],
   "source": [
    "result = pipe(\"illusion.wav\", return_timestamps=True)\n",
    "chunks = result[\"chunks\"]\n",
    "\n",
    "# 將文本內容提取出來\n",
    "text = \"\\n\".join(chunk[\"text\"] for chunk in chunks)\n",
    "\n",
    "# 將文本保存到txt文件中\n",
    "output_file = \"original_lyrics.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(f\"已將輸出的文本保存到 {output_file} 文件中\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
    "    temperature = 0.5\n",
    "    top_p = 0.95\n",
    "    repetition_penalty = 1.15\n",
    "    do_sample = True\n",
    "    max_new_tokens = 400\n",
    "    num_return_sequences = 1\n",
    "\n",
    "    split_chunk_size = 800\n",
    "    split_overlap = 0\n",
    "    \n",
    "    embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "    k = 3\n",
    "    \n",
    "    text_path = '/Users/deyu/Documents/GitHub/Network_Class_File/Network_Class_File/original_lyrics.txt'\n",
    "    Embeddings_path = './faiss_index_py'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id = CFG.model_name,\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": CFG.max_new_tokens,\n",
    "        \"temperature\": CFG.temperature,\n",
    "        \"top_p\": CFG.top_p,\n",
    "        \"repetition_penalty\": CFG.repetition_penalty,\n",
    "        \"do_sample\": CFG.do_sample,\n",
    "        \"num_return_sequences\": CFG.num_return_sequences\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I've been known to miss a red flag\n",
      " I've been known to put my lover on a pedestal\n",
      " In the end, those things just don't last\n",
      " And it's time I take my rose-colored glasses off\n",
      " I already know your type, telling me the things I like\n",
      " Trying to make me yours for life, taking me for a ride\n",
      " I already know your type, think I play your cards right\n",
      " Don't you know I could do this dance all night\n",
      " Ooh, what you doing?\n",
      " Don't know who you think that you're confusing\n",
      " I'd be like, ooh, it's amusing\n",
      " You think I'm gonna fall for an illusion\n",
      " It's all right, it's all right, it's all right\n",
      " And I feel like it's only, it's only, it's only, it's only\n",
      " Was a time when that shit might have worked\n",
      " Was a time when I just threw a match and let it burn\n",
      " Now I'm grown, I know what I deserve\n",
      " But still like that, still with the lessons I already learned\n",
      " I already know your type, telling me the things I like\n",
      " Trying to make me else for life\n",
      " Taking me for a ride\n",
      " I already know your type\n",
      " Think you play your cards right\n",
      " Don't you know I could do this dance all night\n",
      " Ooh, what you doing?\n",
      " Don't know who you think that you're confusing\n",
      " I'd be like ooh, it's amusing\n",
      " You think I'm gonna fall for an illusion\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " It's all great for me\n",
      " Illusion\n",
      " I really like the way you're moving\n",
      " Yeah, I just wanna dance with the illusion\n",
      " Yeah, I just wanna dance with\n",
      " Yeah, I just wanna dance with\n",
      " I could dance all night\n",
      " Oh\n",
      " Ooh, what you doing?\n",
      " Don't know who you think that you're confusing\n",
      " I'd be like, ooh, it's amusing\n",
      " You think I'm gonna fall for an illusion\n",
      " What you doing?\n",
      " Don't know who you think that you're confusing\n",
      " I'd be like, ooh, it's amusing\n",
      " You think I'm gonna fall for an illusion\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 打開文本檔案並讀取內容\n",
    "with open(CFG.text_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 現在你可以對讀取的文本內容進行後續處理\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install textsum\n",
    "#hugging face:https://reurl.cc/xLnXee\n",
    "from textsum.summarize import Summarizer\n",
    "\n",
    "model_name = \"pszemraj/led-large-book-summary\"\n",
    "summarizer = Summarizer(\n",
    "    model_name_or_path=model_name,  # you can use any Seq2Seq model on the Hub\n",
    "    token_batch_length=4096,  # tokens to batch summarize at a time, up to 16384\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 02:03:36 INFO Loaded model pszemraj/long-t5-tglobal-base-16384-book-summary to cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9614822309a34926a3558e67be7b8d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:1005: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: In this short scene, the narrator tells us that he's been known to lose a \"red flag\" in front of his lover, but it's now time for him to take his rose-coloured glasses off and start over again. He says he already knows her type, telling him what he likes trying to make her hiss for life. He asks if you know he can dance all night at the theater. Don't think you're confused. What you doing is amusing. It's just amusing I thought I'm going to fall for my illusion\n"
     ]
    }
   ],
   "source": [
    "from textsum.summarize import Summarizer\n",
    "\n",
    "# 定義文件路徑\n",
    "file_path = \"/Users/deyu/Documents/GitHub/Network_Class_File/Network_Class_File/original_lyrics.txt\"\n",
    "\n",
    "# 讀取文本內容\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 創建 Summarizer 實例\n",
    "summarizer = Summarizer()\n",
    "\n",
    "# 將文本拆分成句子\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "# 提取前幾個句子作為摘要\n",
    "summary_sentences = sentences[:3]\n",
    "\n",
    "# 將摘要句子組合成摘要文本\n",
    "summary = \". \".join(summary_sentences)\n",
    "\n",
    "# 生成摘要\n",
    "result_text = summarizer(summary)\n",
    "print(f\"summary: {result_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install SpeechRecognition\n",
    "! pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**################################**\n",
       "**Audio to Text & Generate Summary**\n",
       "**################################**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a6a8b5855b464a843e1cfc590e0d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Upload Audio File', style=ButtonStyle()), Button(description='Load Audio Fi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5fe60da2224980b6e90c6946e1a02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='100px', width='80%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e71b746241342e7829895de8d6112f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Summary', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb719b9d85424df6b8c0823841b4ff60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='100px', width='80%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 將標題放入粗體且放大的方框中\n",
    "title = \"Audio to Text & Generate Summary\"\n",
    "boxed_title = f\"**{'#' * len(title)}**\\n**{title}**\\n**{'#' * len(title)}**\"\n",
    "\n",
    "# 顯示方框中的標題\n",
    "display(Markdown(boxed_title))\n",
    "\n",
    "# 其他程式碼\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "import speech_recognition as sr\n",
    "from summarizer import Summarizer\n",
    "\n",
    "uploader = None\n",
    "output_text = None\n",
    "result_text = None\n",
    "\n",
    "def browse_file(b):\n",
    "    global uploader\n",
    "    uploader = widgets.FileUpload(accept='.wav,.mp3', multiple=False)\n",
    "    display(uploader)\n",
    "\n",
    "def load_file(b):\n",
    "    global output_text\n",
    "    \n",
    "    # 檢查是否有上傳文件\n",
    "    if uploader is None or len(uploader.value) == 0:\n",
    "        print(\"Please upload an audio file first.\")\n",
    "        return\n",
    "    \n",
    "    # Print the uploader value to understand its structure\n",
    "    print(uploader)\n",
    "    \n",
    "    # 讀取上傳的音頻文件\n",
    "    file_content = next(iter(uploader.value.values()))['content']\n",
    "    \n",
    "    # 使用 SpeechRecognition 進行語音識別\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(file_content) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
    "    \n",
    "    # 將識別的文本顯示在輸入文本框中\n",
    "    output_text.value = text\n",
    "\n",
    "def generate_summary(b):\n",
    "    global uploader, output_text, result_text\n",
    "    \n",
    "    # 檢查是否有上傳文件\n",
    "    if uploader is None or len(uploader.value) == 0:\n",
    "        print(\"Please upload an audio file first.\")\n",
    "        return\n",
    "    \n",
    "    # Print the uploader value to understand its structure\n",
    "    print(uploader)\n",
    "    \n",
    "    # 讀取上傳的音頻文件\n",
    "    file_content = next(iter(uploader.value.values()))['content']\n",
    "    \n",
    "    # 使用 SpeechRecognition 進行語音識別\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(file_content) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
    "    \n",
    "    # 將識別的文本顯示在輸入文本框中\n",
    "    output_text.value = text\n",
    "    \n",
    "    # 生成摘要\n",
    "    summarizer = Summarizer()\n",
    "    summary = summarizer(text, min_length=50, max_length=200)\n",
    "    \n",
    "    # 將摘要顯示在結果文本框中\n",
    "    result_text.value = summary\n",
    "\n",
    "# 上傳按鈕\n",
    "upload_button = widgets.Button(description=\"Upload Audio File\")\n",
    "upload_button.on_click(browse_file)\n",
    "\n",
    "# 讀取文件按鈕\n",
    "load_button = widgets.Button(description=\"Load Audio File\")\n",
    "load_button.on_click(load_file)\n",
    "\n",
    "# 按鈕布局\n",
    "button_layout = widgets.HBox([upload_button, load_button])\n",
    "display(button_layout)\n",
    "\n",
    "# 輸出文本框\n",
    "output_text = widgets.Textarea(layout={'width': '80%', 'height': '100px'})\n",
    "display(output_text)\n",
    "\n",
    "# 生成摘要按鈕\n",
    "generate_button = widgets.Button(description=\"Generate Summary\")\n",
    "generate_button.on_click(generate_summary)\n",
    "display(generate_button)\n",
    "\n",
    "# 結果文本框\n",
    "result_text = widgets.Textarea(layout={'width': '80%', 'height': '100px'})\n",
    "display(result_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
